{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee37a421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 1. 0. 2. 2. 2. 3.]\n",
      " [2. 3. 0. 1. 2. 1. 3.]\n",
      " [3. 3. 0. 1. 0. 2. 3.]\n",
      " [3. 0. 3. 1. 0. 3. 3.]\n",
      " [2. 2. 2. 1. 0. 2. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#MCC\n",
    "import random\n",
    "import numpy as np ;\n",
    "\n",
    "class GridWorld():\n",
    "    def __init__(self):\n",
    "        self.x=0\n",
    "        self.y=0\n",
    "    \n",
    "    def step(self, a):\n",
    "        # 0번 액션: 왼쪽, 1번 액션: 위, 2번 액션: 오른쪽, 3번 액션: 아래쪽\n",
    "        if a==0:\n",
    "            self.move_left() \n",
    "        elif a==1:\n",
    "            self.move_up()\n",
    "        elif a==2:\n",
    "            self.move_right()\n",
    "        elif a==3:\n",
    "            self.move_down()\n",
    "\n",
    "        reward = -1  # 보상은 항상 -1로 고정\n",
    "        done = self.is_done()\n",
    "        return (self.x, self.y), reward, done\n",
    "\n",
    "    def move_left(self):\n",
    "        if self.y==0:\n",
    "            pass\n",
    "        elif self.y==3 and self.x in [0,1,2]:\n",
    "            pass\n",
    "        elif self.y==5 and self.x in [2,3,4]:\n",
    "            pass\n",
    "        else:\n",
    "            self.y -= 1\n",
    "\n",
    "    def move_right(self):\n",
    "        if self.y==1 and self.x in [0,1,2]:\n",
    "            pass\n",
    "        elif self.y==3 and self.x in [2,3,4]:\n",
    "            pass\n",
    "        elif self.y==6:#map 가장끝자리여서\n",
    "            pass\n",
    "        else:\n",
    "            self.y += 1\n",
    "      \n",
    "    def move_up(self):\n",
    "        if self.x==0:\n",
    "            pass\n",
    "        elif self.x==3 and self.y==2:\n",
    "            pass\n",
    "        else:\n",
    "            self.x -= 1\n",
    "\n",
    "    def move_down(self):\n",
    "        if self.x==4:\n",
    "            pass\n",
    "        elif self.x==1 and self.y==4:\n",
    "            pass\n",
    "        else:\n",
    "            self.x+=1\n",
    "\n",
    "    def is_done(self):\n",
    "        if self.x==4 and self.y==6: # 목표 지점인 (4,6)에 도달하면 끝난다\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "      \n",
    "    def reset(self):\n",
    "        self.x = 0\n",
    "        self.y = 0\n",
    "        return (self.x, self.y)\n",
    "\n",
    "class QAgent():\n",
    "    def __init__(self):\n",
    "        self.q_table = np.zeros((5, 7, 4)) # q벨류를 저장하는 변수. 모두 0으로 초기화.\n",
    "        self.eps = 0.9 #엡실론 \n",
    "        self.alpha = 0.01 #알파\n",
    "        \n",
    "    def select_action(self, s):\n",
    "        # eps-greedy로 액션을 선택\n",
    "        x, y = s # s= (x,y)\n",
    "        coin = random.random()\n",
    "        if coin < self.eps: \n",
    "            action = random.randint(0,3) # 0부터 3까지의 정수 난수 생성 , exploration\n",
    "        else:                            #explotation\n",
    "            action_val = self.q_table[x,y,:] #get q-value from all table\n",
    "            action = np.argmax(action_val) # choose optimal q and action\n",
    "        return action\n",
    "\n",
    "    def update_table(self, history):\n",
    "        # 한 에피소드에 해당하는 history를 입력으로 받아 q 테이블의 값을 업데이트 한다\n",
    "        cum_reward = 0\n",
    "        for transition in history[::-1]:\n",
    "            s, a, r, s_prime = transition\n",
    "            x,y = s\n",
    "            # 몬테 카를로 방식을 이용하여 업데이트.\n",
    "            self.q_table[x,y,a] = self.q_table[x,y,a] + self.alpha * (cum_reward - self.q_table[x,y,a])\n",
    "            cum_reward = cum_reward + r \n",
    "\n",
    "    def anneal_eps(self):\n",
    "        self.eps -= 0.03\n",
    "        self.eps = max(self.eps, 0.1)\n",
    "\n",
    "    def show_table(self):\n",
    "        # 학습이 각 위치에서 어느 액션의 q 값이 가장 높았는지 보여주는 함수\n",
    "        q_lst = self.q_table.tolist()\n",
    "        data = np.zeros((5,7))\n",
    "        for row_idx in range(len(q_lst)):\n",
    "            row = q_lst[row_idx]\n",
    "            for col_idx in range(len(row)):\n",
    "                col = row[col_idx]\n",
    "                action = np.argmax(col)\n",
    "                data[row_idx, col_idx] = action\n",
    "        print(data)\n",
    "      \n",
    "def main():\n",
    "    env = GridWorld()\n",
    "    agent = QAgent()\n",
    "\n",
    "    for n_epi in range(1000): # 총 1,000 에피소드 동안 학습\n",
    "        done = False\n",
    "        history = []\n",
    "\n",
    "        s = env.reset() # row=0, col=0\n",
    "        while not done: # 한 에피소드가 끝날 때 까지\n",
    "            a = agent.select_action(s) #select action 0 to 3\n",
    "            s_prime, r, done = env.step(a) #다음 state, reward\n",
    "            history.append((s, a, r, s_prime)) #history에 MDP 저장\n",
    "            s = s_prime #다음 state로 이동\n",
    "        agent.update_table(history) # 히스토리를 이용하여 에이전트를 업데이트\n",
    "        agent.anneal_eps()\n",
    "\n",
    "    agent.show_table() # 학습이 끝난 결과를 출력\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7582fe05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 3. 0. 2. 2. 2. 3.]\n",
      " [3. 3. 0. 2. 2. 2. 3.]\n",
      " [3. 3. 0. 1. 0. 3. 3.]\n",
      " [2. 2. 2. 1. 0. 3. 3.]\n",
      " [2. 1. 2. 1. 0. 2. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Q-learning\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class GridWorld():\n",
    "    def __init__(self):\n",
    "        self.x=0\n",
    "        self.y=0\n",
    "    \n",
    "    def step(self, a):\n",
    "        # 0번 액션: 왼쪽, 1번 액션: 위, 2번 액션: 오른쪽, 3번 액션: 아래쪽\n",
    "        if a==0:\n",
    "            self.move_left()\n",
    "        elif a==1:\n",
    "            self.move_up()\n",
    "        elif a==2:\n",
    "            self.move_right()\n",
    "        elif a==3:\n",
    "            self.move_down()\n",
    "\n",
    "        reward = -1 # 보상은 항상 -1로 고정\n",
    "        done = self.is_done()\n",
    "        return (self.x, self.y), reward, done\n",
    "\n",
    "    def move_left(self):\n",
    "        if self.y==0:\n",
    "            pass\n",
    "        elif self.y==3 and self.x in [0,1,2]:\n",
    "            pass\n",
    "        elif self.y==5 and self.x in [2,3,4]:\n",
    "            pass\n",
    "        else:\n",
    "            self.y -= 1\n",
    "\n",
    "    def move_right(self):\n",
    "        if self.y==1 and self.x in [0,1,2]:\n",
    "            pass\n",
    "        elif self.y==3 and self.x in [2,3,4]:\n",
    "            pass\n",
    "        elif self.y==6:\n",
    "            pass\n",
    "        else:\n",
    "            self.y += 1\n",
    "      \n",
    "    def move_up(self):\n",
    "        if self.x==0:\n",
    "            pass\n",
    "        elif self.x==3 and self.y==2:\n",
    "            pass\n",
    "        else:\n",
    "            self.x -= 1\n",
    "\n",
    "    def move_down(self):\n",
    "        if self.x==4:\n",
    "            pass\n",
    "        elif self.x==1 and self.y==4:\n",
    "            pass\n",
    "        else:\n",
    "            self.x+=1\n",
    "\n",
    "    def is_done(self):\n",
    "        if self.x==4 and self.y==6:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "      \n",
    "    def reset(self):\n",
    "        self.x = 0\n",
    "        self.y = 0\n",
    "        return (self.x, self.y)\n",
    "\n",
    "class QAgent():\n",
    "    def __init__(self):\n",
    "        self.q_table = np.zeros((5, 7, 4)) # 마찬가지로 Q 테이블을 0으로 초기화\n",
    "        self.eps = 0.9\n",
    "\n",
    "    def select_action(self, s):\n",
    "        # eps-greedy로 액션을 선택해준다\n",
    "        x, y = s\n",
    "        coin = random.random()\n",
    "        if coin < self.eps:\n",
    "            action = random.randint(0,3)\n",
    "        else:\n",
    "            action_val = self.q_table[x,y,:]\n",
    "            action = np.argmax(action_val)\n",
    "        return action\n",
    "\n",
    "    def update_table(self, transition):\n",
    "        s, a, r, s_prime = transition\n",
    "        x,y = s\n",
    "        next_x, next_y = s_prime\n",
    "        a_prime = self.select_action(s_prime) # S'에서 선택할 액션 (실제로 취한 액션이 아님)\n",
    "        # Q러닝 업데이트 식을 이용 \n",
    "        self.q_table[x,y,a] = self.q_table[x,y,a] + 0.1 * (r + np.amax(self.q_table[next_x,next_y,:]) - self.q_table[x,y,a])\n",
    "\n",
    "    def anneal_eps(self):\n",
    "        self.eps -= 0.01  # Q러닝에선 epsilon 이 좀더 천천히 줄어 들도록 함.\n",
    "        self.eps = max(self.eps, 0.2) \n",
    "\n",
    "    def show_table(self):\n",
    "        q_lst = self.q_table.tolist()\n",
    "        data = np.zeros((5,7))\n",
    "        for row_idx in range(len(q_lst)):\n",
    "            row = q_lst[row_idx]\n",
    "            for col_idx in range(len(row)):\n",
    "                col = row[col_idx]\n",
    "                action = np.argmax(col)\n",
    "                data[row_idx, col_idx] = action\n",
    "        print(data)\n",
    "      \n",
    "\n",
    "def main():\n",
    "    env = GridWorld()\n",
    "    agent = QAgent()\n",
    "\n",
    "    for n_epi in range(1000):\n",
    "        done = False\n",
    "\n",
    "        s = env.reset()\n",
    "        while not done:\n",
    "            a = agent.select_action(s)\n",
    "            s_prime, r, done = env.step(a)\n",
    "            agent.update_table((s,a,r,s_prime))\n",
    "            s = s_prime\n",
    "        agent.anneal_eps()\n",
    "\n",
    "    agent.show_table()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfa2c631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2. 3. 0. 1. 3. 3. 3.]\n",
      " [2. 3. 0. 2. 2. 3. 3.]\n",
      " [3. 3. 0. 1. 0. 3. 3.]\n",
      " [2. 2. 2. 1. 0. 3. 3.]\n",
      " [3. 1. 2. 1. 0. 2. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class GridWorld():\n",
    "    def __init__(self):\n",
    "        self.x=0\n",
    "        self.y=0\n",
    "    \n",
    "    def step(self, a):\n",
    "        # 0번 액션: 왼쪽, 1번 액션: 위, 2번 액션: 오른쪽, 3번 액션: 아래쪽\n",
    "        if a==0:\n",
    "            self.move_left()\n",
    "        elif a==1:\n",
    "            self.move_up()\n",
    "        elif a==2:\n",
    "            self.move_right()\n",
    "        elif a==3:\n",
    "            self.move_down()\n",
    "\n",
    "        reward = -1  # 보상은 항상 -1로 고정\n",
    "        done = self.is_done()\n",
    "        return (self.x, self.y), reward, done\n",
    "\n",
    "    def move_left(self):\n",
    "        if self.y==0:\n",
    "            pass\n",
    "        elif self.y==3 and self.x in [0,1,2]:\n",
    "            pass\n",
    "        elif self.y==5 and self.x in [2,3,4]:\n",
    "            pass\n",
    "        else:\n",
    "            self.y -= 1\n",
    "\n",
    "    def move_right(self):\n",
    "        if self.y==1 and self.x in [0,1,2]:\n",
    "            pass\n",
    "        elif self.y==3 and self.x in [2,3,4]:\n",
    "            pass\n",
    "        elif self.y==6:\n",
    "            pass\n",
    "        else:\n",
    "            self.y += 1\n",
    "      \n",
    "    def move_up(self):\n",
    "        if self.x==0:\n",
    "            pass\n",
    "        elif self.x==3 and self.y==2:\n",
    "            pass\n",
    "        else:\n",
    "            self.x -= 1\n",
    "\n",
    "    def move_down(self):\n",
    "        if self.x==4:\n",
    "            pass\n",
    "        elif self.x==1 and self.y==4:\n",
    "            pass\n",
    "        else:\n",
    "            self.x+=1\n",
    "\n",
    "    def is_done(self):\n",
    "        if self.x==4 and self.y==6: # 목표 지점인 (4,6)에 도달하면 끝난다\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "      \n",
    "    def reset(self):\n",
    "        self.x = 0\n",
    "        self.y = 0\n",
    "        return (self.x, self.y)\n",
    "\n",
    "class QAgent():\n",
    "    def __init__(self):\n",
    "        self.q_table = np.zeros((5, 7, 4)) # 마찬가지로 Q 테이블을 0으로 초기화\n",
    "        self.eps = 0.9\n",
    "\n",
    "    def select_action(self, s):\n",
    "        # eps-greedy로 액션을 선택해준다\n",
    "        x, y = s\n",
    "        coin = random.random()\n",
    "        if coin < self.eps:\n",
    "            action = random.randint(0,3)\n",
    "        else:\n",
    "            action_val = self.q_table[x,y,:]\n",
    "            action = np.argmax(action_val)\n",
    "        return action\n",
    "\n",
    "    def update_table(self, transition):\n",
    "        s, a, r, s_prime = transition\n",
    "        x,y = s\n",
    "        next_x, next_y = s_prime\n",
    "        a_prime = self.select_action(s_prime) # S'에서 선택할 액션 (실제로 취한 액션이 아님)\n",
    "        # SARSA 업데이트 식을 이용\n",
    "        self.q_table[x,y,a] = self.q_table[x,y,a] + 0.1 * (r + self.q_table[next_x,next_y,a_prime] - self.q_table[x,y,a])\n",
    "\n",
    "    def anneal_eps(self):\n",
    "        self.eps -= 0.03\n",
    "        self.eps = max(self.eps, 0.1)\n",
    "\n",
    "    def show_table(self):\n",
    "        q_lst = self.q_table.tolist()\n",
    "        data = np.zeros((5,7))\n",
    "        for row_idx in range(len(q_lst)):\n",
    "            row = q_lst[row_idx]\n",
    "            for col_idx in range(len(row)):\n",
    "                col = row[col_idx]\n",
    "                action = np.argmax(col)\n",
    "                data[row_idx, col_idx] = action\n",
    "        print(data)\n",
    "\n",
    "      \n",
    "def main():\n",
    "    env = GridWorld()\n",
    "    agent = QAgent()\n",
    "\n",
    "    for n_epi in range(1000):\n",
    "        done = False\n",
    "\n",
    "        s = env.reset()\n",
    "        while not done:\n",
    "            a = agent.select_action(s)\n",
    "            s_prime, r, done = env.step(a)\n",
    "            agent.update_table((s,a,r,s_prime))\n",
    "            s = s_prime\n",
    "        agent.anneal_eps()\n",
    "\n",
    "    agent.show_table()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4f63b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
